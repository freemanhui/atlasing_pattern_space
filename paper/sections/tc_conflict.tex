\subsection{Domain-Specificity Analysis: The Failure of Topology Preservation in Low-Dimensional Settings}\label{sec:tc_conflict}

To directly probe the interaction between topology preservation (T) and causal invariance (C), we designed a synthetic experiment where these objectives might conflict. We created a \textbf{Colored Clusters} dataset where the primary geometric structure is defined by spurious color features, forcing a potential trade-off: preserving input-space topology would maintain color-based clustering, while enforcing causal invariance would require discarding color information.

\subsubsection{Experimental Setup}

\textbf{Dataset:} Synthetic 2D shape features with one-hot encoded color (2D shape + 10D color). Two classes are distinguished by shape, but each class is spuriously correlated with 5 specific colors (e.g., Class 0: red/orange/yellow; Class 1: blue/green). Training environments have 80\% color-label correlation; test environment has independent color distribution.

\textbf{Hyperparameter Sweep:} We trained models across a $6 \times 6$ grid of $(\lambda_T, \lambda_C) \in \{0, 0.1, 0.5, 1.0, 2.0, 5.0\}$ to map the full trade-off landscape (36 configurations total).

\textbf{Metrics:}
\begin{itemize}
    \item \textbf{Causal Accuracy}: Classification accuracy ignoring spurious color features
    \item \textbf{Topology Preservation}: kNN Jaccard similarity between input and latent space
    \item \textbf{Color Reliance}: Correlation between latent codes and color features (lower is better)
    \item \textbf{Test Accuracy}: Overall classification performance
\end{itemize}

\subsubsection{Results}

Table~\ref{tab:tc_conflict} presents results for key configurations, and Figure~\ref{fig:tc_heatmaps} shows the complete trade-off landscape across all $(\lambda_T, \lambda_C)$ pairs.

\input{tables/tc_conflict_table}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\textwidth]{figures/tc_heatmaps.png}
  \caption{Heatmaps showing how causal accuracy, topology preservation, color reliance, and test accuracy vary across $\lambda_T \times \lambda_C$ configurations. Topology preservation remains at 0\% across all settings, while causality component reduces color reliance by $\sim$4pp.}
  \label{fig:tc_heatmaps}
\end{figure}

\textbf{Key Findings:}

\begin{enumerate}
    \item \textbf{Causality component works as intended}: Increasing $\lambda_C$ improves causal accuracy from 83.1\% (baseline) to 84.2\% (best), reducing spurious color reliance from 65.1\% to 61.0\%. The benefit saturates around $\lambda_C = 1-5$.
    
    \item \textbf{Topology component failed}: Topology preservation remained at 0\% across \emph{all} $\lambda_T$ values, including $\lambda_T=5.0$. This indicates the topology loss did not engage in this setting, either due to insufficient batch size (64 vs k=8), incompatibility with low-dimensional synthetic features, or implementation issues.
    
    \item \textbf{No observed trade-off}: Because topology preservation never activated, we could not empirically validate the hypothesized T-C conflict. The expected trade-off---where maximizing topology preservation would compete with causal invariance---was not observed. Figure~\ref{fig:tc_pareto} visualizes this failure, showing all 36 configurations clustered at 0\% topology preservation regardless of $\lambda_T$ values.
    
    \item \textbf{Marginal improvements overall}: Even the best configuration ($\lambda_T=0, \lambda_C=5$) achieved only +1.1pp improvement over baseline (84.2\% vs 83.1\%), suggesting the synthetic task was not sufficiently challenging to expose clear regularization benefits.
\end{enumerate}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.6\textwidth]{figures/tc_pareto_frontier.png}
  \caption{Pareto frontier plot showing relationship between topology preservation and causal accuracy. All points cluster at 0\% topology preservation, indicating the topology component did not function as intended in this setting.}
  \label{fig:tc_pareto}
\end{figure}

\subsubsection{Analysis: Why Did Topology Fail?}

Post-hoc investigation identified several potential causes for the topology component's failure:

\textbf{1. Low-dimensional features:} The synthetic dataset used only 2D shape features. Unlike MNIST's 784-dimensional pixel space where kNN structure is rich and meaningful, 2D features may not have sufficient complexity for topology preservation to provide measurable benefits.

\textbf{2. Batch size vs. k parameter:} With batch size 64 and k=8, only 12.5\% of each batch participates in kNN relationships. This may be insufficient for stable gradient signals from the topology loss.

\textbf{3. Distance metric mismatch:} The topology loss uses $\ell^2$ distance on concatenated shape+color features. In this space, color dominates due to one-hot encoding sparsity, potentially making kNN graphs uninformative for shape-based topology.

\textbf{4. Possible implementation bug:} While the topology loss worked on MNIST (Section~\ref{sec:experiments}), it may have issues specific to this dataset structure that we did not identify.

\subsubsection{Implications and Lessons}

This \textbf{negative result} provides valuable scientific insights about the domain-specificity of geometric regularization:

\textbf{Topology Preservation is Not Universal:} While topology preservation improved kNN fidelity in MNIST experiments (see Section~\ref{sec:experiments}), it failed completely in this low-dimensional synthetic setting. This demonstrates that:
\begin{itemize}
    \item Topology preservation requires \textbf{high-dimensional embeddings} with meaningful distance structure
    \item It may not apply to \textbf{low-dimensional synthetic features} (2D shapes)
    \item Batch size and k-NN parameters must be \textbf{carefully tuned} for the data modality
    \item Geometric constraints should be \textbf{validated per-domain} rather than assumed universal
\end{itemize}

\textbf{Honest Reporting Strengthens Science:} Rather than hiding this failure, we report it transparently to help the community understand when topology preservation helps. This aligns with our broader message: \emph{regularization components are not universally beneficial but require careful domain-specific validation}.

\textbf{Causality Component Validated:} Despite topology's failure, the causality component worked as expected, providing modest but consistent improvements in reducing spurious feature reliance. This validates the modularity of the APS framework---components can be used independently when appropriate.
